\section{Unit 2}
\subsection{Lecture 3}
\subsubsection{Monotonicity on Maximal Intervals}
\begin{defbox}{Equilibrium Points and Steady State Solutions}{}
    If ${v}$ is a vector field on $\RR$ and $v(x_0)=0$, then $x_0$ is called an \textbf{equilibrium point} of $v$. For any $t_0 \in \RR$, the function $x(t) = x_0$ for all $t$ is a solution of the IVP
    \[
        x'(t) = v(x(t)), \quad x(t_0) = x_0. 
    \]
    Such a constant solution is called a \textbf{steady state solution} for $x'(t) = v(x(t))$.
\end{defbox}

\begin{defbox}{Maximal Intervals}{}
    An interval $(a, b)$ is a maximal interval for $v$ if $v(x) \neq 0$ for all $x \in (a, b)$ and if either $a = -\infty$ or $v(a) = 0$ and either $b = \infty$ or $v(b) = 0$.
\end{defbox}

For example, consider $v: \RR \to \RR$ given by 
\[
    v(x) = x(1-x).
\]
Then, $v$ will have three maximal intervals. Namely $(-\infty, 0), (0, 1)$ and, $(1, \infty)$. Note that these maximal intervals were found by setting $v(x) = 0$ and solving for $x$ as the defining characteristic of a maximal interval is $v(x) \neq 0$.

\begin{defbox}{Monotone functions}{}
    Let $f: A \to B$ be a function. Then, $f$ is said to be \textbf{monotone increasing} if, and only if, 
    \[
        x_1 < x_2 \Rightarrow f(x_1) \leq f(x_2).
    \] 
    Similarly, $f$ is \textbf{monotone decreasing} if, and only if, 
    \[
        x_1 < x_2 \Rightarrow f(x_1) \geq f(x_2). 
    \]
    As well, $f$ is \textbf{strictly} monotone increasing if, and only if, 
    \[
        x_1 < x_2 \Rightarrow f(x_1) < f(x_2), 
    \]
    and \textbf{strictly} monotone decreasing if, and only if, 
    \[
        x_1 < x_2 \Rightarrow f(x_1) > f(x_2).
    \]
\end{defbox}
\begin{impbox}{Fact}{\label{fact:1}}
    Let $f: A \to B$ be a function. If $f$ is strictly monotone increasing or decreasing on an interval $(a, b) \subseteq A$, then the inverse function $f^{-1}: B \to A$ exists.
\end{impbox}

Suppose $(a, b)$ is a maximal interval for $v$ and $x_0 \in (a, b)$. Then $v(x_0) \neq 0$ by definition of a maximal interval. Now, assume that $v(x_0) > 0$. Since $v$ is continuous and $v(x) \neq 0$ through $(a, b)$, we can apply the intermediate value theorem to see that $v(x) > 0$ on $(a, b)$. It follows that $x(t)$ must be strictly increasing on $(a, b)$ since 
\[
    x'(t) = v(x(t)).
\]
A similar statement can be made for $v(x_0) < 0$ and $x(t)$ being strictly decreasing. Thus, $x(t)$ is strictly monotone (either increasing or decreasing) over $(a, b)$ and hence is an invertible function onto its range. We denote the inverse function $t(x)$.

We define 
\[
    T_a = \lim_{x\to\,a}t(x) \quad\text{and}\quad T_b = \lim{x\to\,b}t(x)
\]
under the assumption that $v$ is positive on $(a, b)$ and that $x(t)$ and $t(x)$ both exist and are strictly increasing functions. Then, $x(t)$ is invertible from $(T_a, T_b)$ onto $(a, b)$ with $t(x)$ going the opposite way. \\ If $v$ is negative, and thus $x(t)$ and $t(x)$ are decreasing functions, then simply swap $T_a$ and $T_b$ such that $x(t)$ is invertible from $(T_b, T_a)$ onto $(a, b)$ and $t(x)$ invertible from $(a, b)$ onto $(T_a, T_b)$.

\begin{example}{Solution on a Maximal Interval}{}{}
    Consider the differential equation 
    \[
        v(x) = x'(t) = x(1-x), \quad x(t_0) = x_0 \in (0, 1).
    \]
    As previously mentioned, we know that $(0, 1)$ is a maximal interval for $v$. Observe that 
    \[
        \frac{1}{x(1-x)} = \frac{1}{x}+ \frac{1}{1-x} = \frac{d}{dx}\left[\ln\left(\frac{x}{1-x}\right)\right].
    \] 
    If we define 
    \[
        y = F(x) = \ln\left(\frac{x}{1-x}\right)
    \]
    then, 
    \begin{equation}{\label{eq:6}}
        \frac{d}{dt}F(x(t)) = 1 
    \end{equation}
    because 
    \begin{align*}
        \frac{d}{dt}F(x(t)) &= F'(x(t))x'(t) \\
        &= \frac{d}{dt}\left[\ln\left(\frac{x}{1-x}\right)\right]x'(t) \\
        &= \frac{1}{x(1-x)} \cdot x(1-x) = 1.
    \end{align*}
    Now, integrating both sides of~(\ref{eq:6}), 
    \begin{equation}{\label{eq:8}}
        \int_{t_{0}}^{t} \frac{d}{dt}F(x(t))\,dt = \int_{t_{0}}^{t}\,dt \Rightarrow F(x(t)) - F(x(t_0)) = t - t_0 \Rightarrow F(x(t)) = F(x_0) + t - t_0,
    \end{equation}
    recalling that $x(t_0) = x_0$. In order to solve this for $x(t)$ start by noticing that 
    \begin{align*}
        F(x) = y &\Rightarrow y = \ln\left(\frac{x}{1-x}\right) \\
        &\Rightarrow e^y = \frac{x}{1-x} \\
        &\Rightarrow e^{y}(1-x) = x \\
        &\Rightarrow e^{y} = x + e^{y}x \\
        &\Rightarrow \frac{e^{y}}{1 + e^{y}} = x.
    \end{align*}
    Since $y = F(x) = F(x_0) + t - t_0$, 
    \begin{align}
        x &= \frac{e^{y}}{1 + e^{y}} \nonumber\\
        &= \frac{e^{F(x_0) + t - t_0}}{1 + e^{F(x_0) + t - t_0}} \nonumber\\
        &= \frac{e^{F(x_0)}e^{t - t_0}}{1 + e^{F(x_0)}e^{t - t_0}}. {\label{eq:7}}
    \end{align}
    But 
    \[
        e^{F(x_0)} = e^{\ln\left(\frac{x_0}{1-x_0}\right)} = \frac{x_0}{1-x_0}.
    \]
    Applying this to~(\ref{eq:7}) and simplifying we can see that 
    \begin{align*}
        \frac{e^{F(x_0)e^{t - t_0}}}{1 + e^{F(x_0)}e^{t - t_0}}&= \frac{\frac{x_0}{1-x_0}e^{t-t_0}}{1 + \frac{x_0}{1-x_0}e^{t-t_0}} \\
        &= \frac{x_{0}e^{t-t_0}}{(1-x_0) + x_{0}e^{t-t_0}}.
    \end{align*}
    It should be clear that $x(t_0) = x_0$. Since the denominator will never be $0$, it follows that $x(t)$ is defined for all $t$. Because 
    \[
        \lim_{t\to\,-\infty}x(t) = 0 \quad\text{and}\quad \lim_{t\to\,\infty} = 1, 
    \]
    we can see that $x(t)$ is a strictly monotone increasing function from $(-\infty, \infty)$ onto $(0, 1)$. Thus, the inverse function $t(x)$ must exist (from the earlier fact). Solving~(\ref{eq:8}) for $t$ we can see that 
    \[
        t(x) = t_0 + F(x) - F(x_0),
    \]
    but, 
    \[
        F(x) = \frac{1}{v} \Rightarrow F(x) - F(x_0) = \int_{x_0}^{x} \frac{1}{v(z)}\,dz. 
    \]
    So, 
    \[
        t(x) = t_0 + \int_{x_0}^{x}\frac{1}{v(z)}\,dz
    \]
    with 
    \[
        \int_{x_0}^{1}\frac{1}{v(z)}dz = \infty \quad\text{and}\quad \int_{x_0}^{0}\frac{1}{v(z)}dz = -\infty 
    \]
    for any $x_0 \in (0, 1)$. This implies that $T_0 = -\infty$ and $T_1 = \infty$.
\end{example}

\newpage 

\subsubsection{Lipschitz Continuity}
\begin{defbox}{Metric Spaces}{}
    A metric space is a double $M = (M, d)$ that consists of a set $M$ and a distance \textit{metric}, $d$. In order for $M$ to be a metric space, the distance metric must satisfy the following axioms:
    \begin{enumerate}
        \item Non-negativity: For any $x, y \in M,\,d(x,y) \geq 0$
        \item Identity: For any $x, y \in M,\, d(x, y) = 0 \Leftrightarrow x=y$
        \item Symmetry: For any $x, y \in M\, d(x, y) = d(y, x)$
        \item Triangle Inequality: For any $x, y, z \in M$ 
        \[
            d(x, z) \leq d(x, y) + d(y, z) 
        \]
    \end{enumerate}
\end{defbox}
The prototypical metric space is $\RR^{n}$ with the euclidean metric (the standard distance formula). 
\begin{defbox}{Lipschitz Continuity}{}
    Let $f: X \to Y$ be a function between metric spaces. It is $L$-Lipschitz if there is a constant $L > 0$ such that for any $x_1, x_2 \in X$
    \[
        d_{y}(f(x_1), f(x_2)) \leq L \cdot d_{x}(x_1, x_2) 
    \]
    where $d_x$ and $d_y$ are the metrics for $X$ and $Y$ respectively.
\end{defbox}

\begin{impbox}{Fact}
    If $f: (a, b) \to \RR^{n}$ is differentiable and 
    \[
        |f'(x)| \leq L, \quad\forall x \in (a, b)
    \]
    then, $f$ is $L$-Lipschitz continuous. Formally, if $f$ is $L$-Lipschitz continous on $(a, b)$ then 
    \[
        |f(x) - f(y)| \leq L|x-y|, \quad \forall x,y \in (a, b).
    \]
\end{impbox}
We can prove this fact as follows. 
\begin{proof}
    Let $x, y \in (a, b)$ such that $x < y$ and assume that $|f'(x)| \leq L$. By the Mean Value Theorem, 
    \[
        f(y) - f(x) = f'(c)(y - x) 
    \]
    for $c \in (x, y)$. So, 
    \[
        |f(y) - f(x)| \leq L|y - x| 
    \]
\end{proof}

\newpage 

\subsection{Lecture 4}
\subsubsection{Barrows Formula}
\begin{thm}{}{}
    Let $v$ be continous and let $(a, b)$ be a maximal interval for $v$ and $x_0 \in (a, b)$. Fix any $t_0 \in \RR$ and define $t(x)$ on $(a, b)$ by 
    \begin{equation}{\label{eq:9}}
        t(x) = t_0 + \int_{x_{0}}^{x} \frac{1}{v(z)}\,dz.
    \end{equation}
    Then $t(x)$ is a strictly montone function on $(a, b)$ so that 
    \begin{equation}{\label{eq:10}}
        T_a = \lim_{x \downarrow a} t(x) \quad\text{and}\quad T_b = \lim_{x \uparrow b} t(x)
    \end{equation}
    both exist. \\
    If $v$ is positive on $(a, b)$ then $T_a < t_0 < T_b$, and if $x(t)$ is the inverse function to $t(x)$, then $x(t)$ is a solution of 
    \begin{equation}{\label{eq:11}}
        x'(t) = v(x(t)), \quad x(t_0) = x_0.
    \end{equation}
    Moreover, every solution to~(\ref{eq:11}) that is defined on any subinterval of $(T_a, T_b)$ containing $t_0$ equals the restriction of $x(t)$ to this subinterval. In particular, there is a unique solution of~(\ref{eq:11}) defined on $(T_a, T_b)$. If $v$ is negative on $(a, b)$ the same conclusion is valid provided we interchange $T_a$ and $T_b$.
    \begin{proof}
        We first suppose that $v$ is positive on $(a, b)$ and define the function $t(x)$ on $(a, b)$ by Barrows formula~(\ref{eq:9}). For any $x \in (a, b)$ that isn't $x_0$, let $J$ be the closed interval with endpoint $x$ and $x_0$, which is either $[x_0, x]$ in the case $x_0 < x < b$, or else $[x, x_0]$ in the case $a < x < x_0$. \\
        Since $v$ is continuous on $J$, it has a minimum value attaained somewhere in $J$, and since $v$ is positive everywhere on $(a, b)$, and hence everywhere on $J$, there is a $c > 0$ so that $v(x) \geq c$ for all $x \in J$. There fore $1/v(x)$ is continuous and bounded on $J$. It follows that 
        \[
            \int_{x_0}^{x}\frac{1}{v(z)}\,dz
        \]       
        is a proper integral for each $x \in (a, b)$. Thus, 
        \[
            t(x) = t_0 + \int_{x_{0}}^{x} \frac{1}{v(z)}\,dz
        \]
        does define a function on $(a, b)$. By the Fundamental Theorem of Calculus, this function is differentiable, and 
        \begin{equation}{\label{eq:12}}
            \frac{d}{dx}t(x) = \frac{1}{v(z)}. 
        \end{equation}
        Since the right hand side is continuous, $t(x)$ is continuously differentiable on $(a, b)$. Since $v(x) > 0$ on $(a, b)$, $t(x)$ is strictly monotone increasing on $(a, b)$. Therefore, the limit defining $T_a$ and $T_b$ in~(\ref{eq:10}) both exist with $T_a = -\infty$ and $T_b = \infty$ allowed, and $t(x)$ is an invertible function from $(a, b)$ onto $(T_a, T_b)$. Since $t(x)$ is differentiable, by the Inverse Function Theorem, $x(t)$ is differentiable and 
        \[
            \frac{d}{dt} x(t) = \left.\left(\frac{d}{dx}t(x)\right)^{-1}\right|_{x = x(t)}.
        \]
        By~(\ref{eq:12})
        \[
            \left.\left(\frac{d}{dx}t(x)\right)^{-1}\right|_{x = x(t)} = v(x(t))
        \]
        which shows that $x'(t) = v(x(t))$, and clearly $t(x_0) = t_0$, so $x(t_0) = x_0$. \\
        Now suppose that $y(t)$ is a continuously differentiable function defined on some interval $(S, T)$ with $t_0 \in (S, T)$. Suppose also that 
        \[
            y'(t) = v(y(t)) \quad\text{and}\quad y(t_0) = x_0, 
        \]
        and that $y(t) \in (a, b)$ for all $t \in (S, T)$. \\
        Then, for alll $t \in (S, T)$, $y'(t) = v(y(t)) > 0$ and so $y(t)$ is  strictly increasing monotone and hence it is an invertible function from $(S, T)$ onto its range. Let $t(y)$ be the inverse function. By the Inverse Function Theorem, $t(y)$ is differentiable and 
        \[
            \frac{d}{dy} t(y) = \left.\left(\frac{d}{dt}y(t)\right)^{-1}\right|_{t=y(t)} = \frac{1}{v(y)}.
        \]
        Then, by the Fundamental Theorem of Calculus, 
        \[
            t(y) - t(x_0) = \int_{x_{0}}^{y} \frac{1}{v(z)}\,dz 
        \]
        for all $y$ such that $y=y(t)$ for some $t \in (S, T)$. That is, $t(y)$ is given by Barrows formula and hence $y(t)$ is the inverse of the function defined by Barrow's formula. In other words, $y(t) = x(t)$ on its domain of definiton $(S, T)$. THis proves the uniqueness of the solution - for as long as it stays inside $(a, b)$. 
    \end{proof}
\end{thm}

\subsubsection{Existance and Uniqueness for First Order Autonomous Equations}
Let $v$ be continuous and strictly positive on $(a, b)$ with $v(a) = v(b) = 0$. We can apply Barrows formula to compute $T_a$ and $T_b$ subject to $x(t_0) = x_0$ for any $x_0 \in (a, b)$. For example, 
\[
    T_b = \int_{x_{0}}^{b} \frac{1}{v(z)}\, dz.
\]
However, since $v(b) = 0$, 
\[
    T_b = t_0 + \lim_{x \to b}\int_{x_{0}}^{x}\frac{1}{v(z)}\, dz
\]
which is either convergent or divergent. If it is divergent, 
\[
    \lim_{x \to b}\int_{x_{0}}^{x}\frac{1}{v(z)}\, dz = \infty
\]
in which case it takes an infinitely long time for the solutions $x(t)$ to reach the endpoint $b$ of the maximal interval. Thus, the solution exists and remains in $(a, b)$ for all $t > t_0$ if, and only if, 
\[
    \int_{x_{0}}^{b}\frac{1}{v(z)}\,dz < \infty.
\]
A similar analysis shows that $T_a > -\infty$, and thus the solution exists and remains in $(a, b)$ for all $t < t_0$ if, and only if, 
\[
    \int_{x_{0}}^{a}\frac{1}{v(z)}\, dz = -\int_{a}^{x_{0}}\frac{1}{v(z)}\,dz > -\infty.
\]
\begin{thm}{}{\label{thm:2.2}}
    Let $v$ be continuous and strictly positive on a maximal interval $(a, b)$. Then for any $t_0$ and any $x_0 \in (a, b)$, $x'(t) = v(x(t))$ with $x(t_0) = x_0$ has a unique solution that is defined for all $t$, and remains in $(a, b)$ for all $t \in \RR$ if, and only if, 
    \[
        \int_{a}^{x_0} \frac{1}{|v(z)|}\,dz = \int_{x_{0}}^{b}\frac{1}{|v(z)|}\, dz = \infty
    \]
\end{thm}

\begin{thm}{}{}
    Let $v(x)$ be continuous on $(a - \delta, a + \delta), \delta > 0$ and suppose that the only solution of $v(x) = 0$ in $(a - \delta, a + \delta)$ is $x = a$. Then, for any $t_0$, there is a solution of $x'(t) = v(x(t))$ for all $t$ if, and only if, either $v(x) > 0$ on $(a, a + \delta)$ and 
    \[
        \int_{a}^{a+\delta} \frac{1}{v(z)}\, dz < \infty 
    \]
    is satisfied, in which case there is a solution morving right or $v(x) < 0$ on $(a - \delta, a)$ and 
    \[
        \int_{a}^{a - \delta} \frac{1}{v(z)}\, dz < \infty 
    \]
    is satisfied, in which case there's a solution moving to the left. In particular, if 
    \[
        \int_{a - \delta}^{a} \frac{1}{|v(z)|}\, dz = \int_{a}^{a + \delta} \frac{1}{|v(z)|}\,dz = \infty,
    \]
    then the steady state solution is the unique solution.
\end{thm}

Consider the vector field $v: \RR \to \RR$ defined by 
\[
    v(x) = \begin{cases}
        \sqrt{x^2 - 1}, &\quad \text{if } x < -1 \\
        \sqrt{1 - x^2}, &\quad \text{if } -1 \leq x \leq x \\
        \sqrt{x^2 - 1}, &\quad \text{if } x > 1
    \end{cases} 
\]
It is easy to check that $v$ is continous and that $(-\infty, -1), (-1, 1), (1, \infty)$ are max intervals for $v$. Consider the IVP $x'(t) = v(x(t)), x(0) = 0$. By Barrows formula, 
\begin{align*}
    t(x) &= t_0 + \int_{x_{0}}^{x} \frac{1}{v(z)}\,dz \\
    &= \int_{0}^{x} \frac{1}{\sqrt{1 - x^2}}\, dz = \arcsin(x) \quad \forall x \in (-1, 1).
\end{align*}
So, $x(t) = \sin t$ for $t \in \left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$. Then 
\[
    \lim_{x \to -\frac{\pi}{2}} x(t) = -1 \quad\text{and}\quad \lim_{x \to \frac{\pi}{2}} x(t) = 1
\]
thus, $T_{-1} = -\frac{\pi}{2}$ and $T_{1} = \frac{\pi}{2}$. So, on $(T_{-1}, T_{1})$ the solution is unique. However, there are infinitely many choices to continue the solution $(T_{-1}, T_{1})$. Since $v(\pm 1) = 0$, the solution is instantaneously at rest at $x = \pm 1$. One solution is to let it stay at rest: 
\[
    x(t) = \begin{cases}
        -1, &\quad \text{if } t < -\frac{\pi}{2} \\
        \sin t, &\quad \text{if } -\frac{\pi}{2} \leq t \leq \frac{\pi}{2} \\
        1, &\quad \text{if } t > \frac{\pi}{2}
    \end{cases}
\]
For $x > 1$, we can integrate $\displaystyle\frac{1}{v(z)} = \frac{1}{\sqrt{x^2 - 1}}$ using Barrows Formula. Consider the IVP $x'(t) = v(x(t))$, $x\left(\frac{\pi}{2}\right) = 1$, for $t > \frac{\pi}{2}$. By Barrow's formula 
\[
    t(x) = \frac{\pi}{2} + \int_{1}^{x}\frac{1}{\sqrt{z^2 - 1}}\, dz = \frac{\pi}{2} + \ln\left(x + \sqrt{x^2 - 1}\right).
\]
Hence, 
\[
    x + \sqrt{x^2 - 1} = e^{t - \pi/2}.
\]
Let $a = e^{t - \pi/2}$. 
\begin{align*}
    &\Rightarrow x + \sqrt{x^2-1} = a \\
    &\Rightarrow \sqrt{x^2-1} = a - x \\
    &\Rightarrow x^2 - 1 = (a - x)^2 \\
    &\Rightarrow x = \frac{a^2 + 1}{2a} = \cosh\left(t - \frac{\pi}{2}\right).
\end{align*}
We have another solution for the IVP: 
\[
    x(t) = \begin{cases}
        -1, &\quad \text{if } t < -\frac{\pi}{2} \\
        \sin t, &\quad \text{if }, -\frac{\pi}{2} \leq t \leq \frac{\pi}{2} \\
        \cosh t, &\quad \text{if } t > \frac{\pi}{2}
    \end{cases}
\]

\subsubsection{Existance and Uniqueness within Maximal Intervals}
Let $(a, b)$ be a maximal interval for an $L$-Lipschitz vector field $v$ on $\RR$. For any $x_0 \in (a, b)$ the solution of the IVP $x'(t) = v(x(t))$, $x(t_0) = x_0$ exists and is well-defined for all $t \in \RR$. In particular for every $t_0 \in \RR$. In particular for every $t_0 \in \RR$, $x_0 \in (a, b)$, there is a unique solution curve of the IVP passing through $(t_0, x_0)$. 
\begin{proof}
    For simplicity assume $v(x) > 0$ on $(a, b)$, so the solution of the IVP is increasing. We now show that $x(t) < b$ for all $t \in \RR$. Since $x(t)$ is increasing, we only need to consider $t > t_0$, since otherwise $x(t) \leq x_0 < b$. There are two cases. Suppose $b = \infty$. Since $v$ is $L$-Lipschitz for all $z > x_0$, 
    \[
        v(z) - v(x_0) \leq |v(z) - v(x_0)| \leq L|z - x_0| = L(z - x_0).
    \]
    So, $v(z) \leq v(x_0) + L(z - x_0)$. By Barrows formula we have that 
    \begin{align*}
        t(x) &= t_0 + \int_{x_{0}}^{x} \frac{1}{v(z)}\,dz \\
        &\geq t_0 + \int_{x_{0}}^{x} \frac{1}{v(x_0) + L(z - x_0)}\, dz \\
        &= t_0 + \frac{1}{L}\ln\left(\frac{1 + L(z - x_0)}{v(x_0)}\right)
    \end{align*}
    for all $x > x_0$. Since, 
    \[
        \lim_{x \to \infty} \frac{1}{L}\ln\left(\frac{1 + L(z - x_0)}{v(x_0)}\right) = \infty \Rightarrow \lim_{x \to \infty} t(x) = \infty
    \]
    therefore, $x(t) < b = \infty$ for all $t$. \\
    Now assume $b < \infty$. We know $v(b) = 0$ so by Thm~(\ref{thm:2.2}) we need to show 
    \[
        \int_{x_{0}}^{b}\frac{1}{v(z)}\, dz = \infty.
    \]
    The $L$-Lipschitz condition gives 
    \begin{align*}
        v(z) &= v(z) - v(b) \\
        &= |v(z) - v(b)| \\
        &\leq L|z - b| = L(z - b)
    \end{align*}
    So, $v(z) \leq L(b - z)$ and 
    \[
        \int_{x_{0}}^{b} \frac{1}{v(z)}\,dz \geq \int_{x_{0}}^{b} \frac{1}{L(b - z)}\, dz = \infty.
    \]
    Similar, $x(t) > a$ for all $t$ (regardless if $a = -\infty$ or $a > -\infty$).
\end{proof}